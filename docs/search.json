[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini-Project #01",
    "section": "",
    "text": "Code\nif(!dir.exists(file.path(\"data\", \"mp01\"))){\n    dir.create(file.path(\"data\", \"mp01\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nGLOBAL_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"global_top10_alltime.csv\")\n\nif(!file.exists(GLOBAL_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv\", \n                  destfile=GLOBAL_TOP_10_FILENAME)\n}\n\nCOUNTRY_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"country_top10_alltime.csv\")\n\nif(!file.exists(COUNTRY_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv\", \n                  destfile=COUNTRY_TOP_10_FILENAME)\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Projects for STA 9750 at Baruch College",
    "section": "",
    "text": "Welcome!\nHey all, my name is Lincon and I am a graduate student majoring in Quantitative Methods and Modeling.\nI am building this site throughout the semester to showcase all of the project work we are doing in STA9750.\nI am looking forward to actively updating it throughout the semester!"
  },
  {
    "objectID": "mp01.html#task-1-data-acquisition",
    "href": "mp01.html#task-1-data-acquisition",
    "title": "Mini-Project #01",
    "section": "",
    "text": "Code\nif(!dir.exists(file.path(\"data\", \"mp01\"))){\n    dir.create(file.path(\"data\", \"mp01\"), showWarnings=FALSE, recursive=TRUE)\n}\n\nGLOBAL_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"global_top10_alltime.csv\")\n\nif(!file.exists(GLOBAL_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv\", \n                  destfile=GLOBAL_TOP_10_FILENAME)\n}\n\nCOUNTRY_TOP_10_FILENAME &lt;- file.path(\"data\", \"mp01\", \"country_top10_alltime.csv\")\n\nif(!file.exists(COUNTRY_TOP_10_FILENAME)){\n    download.file(\"https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv\", \n                  destfile=COUNTRY_TOP_10_FILENAME)\n}"
  },
  {
    "objectID": "mp01.html#data-import-and-preparation",
    "href": "mp01.html#data-import-and-preparation",
    "title": "Mini-Project #01",
    "section": "Data Import and Preparation",
    "text": "Data Import and Preparation\n\n\nCode\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.1     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(readr)\nlibrary(dplyr)\n\nGLOBAL_TOP_10 &lt;- read_tsv(GLOBAL_TOP_10_FILENAME)\n\n\nRows: 8880 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (3): category, show_title, season_title\ndbl  (5): weekly_rank, weekly_hours_viewed, runtime, weekly_views, cumulativ...\ndate (1): week\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nCOUNTRY_TOP_10 &lt;- read_tsv(COUNTRY_TOP_10_FILENAME)\n\n\nRows: 413620 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (5): country_name, country_iso2, category, show_title, season_title\ndbl  (2): weekly_rank, cumulative_weeks_in_top_10\ndate (1): week\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nstr(GLOBAL_TOP_10)\n\n\nspc_tbl_ [8,880 × 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ week                      : Date[1:8880], format: \"2025-09-28\" \"2025-09-28\" ...\n $ category                  : chr [1:8880] \"Films (English)\" \"Films (English)\" \"Films (English)\" \"Films (English)\" ...\n $ weekly_rank               : num [1:8880] 1 2 3 4 5 6 7 8 9 10 ...\n $ show_title                : chr [1:8880] \"KPop Demon Hunters\" \"Ruth & Boaz\" \"The Wrong Paris\" \"Man on Fire\" ...\n $ season_title              : chr [1:8880] \"N/A\" \"N/A\" \"N/A\" \"N/A\" ...\n $ weekly_hours_viewed       : num [1:8880] 32200000 15900000 13500000 15700000 11200000 8400000 6800000 6200000 4900000 8400000 ...\n $ runtime                   : num [1:8880] 1.67 1.55 1.78 2.43 1.83 ...\n $ weekly_views              : num [1:8880] 19300000 10300000 7600000 6500000 6100000 4900000 3600000 3200000 3200000 2800000 ...\n $ cumulative_weeks_in_top_10: num [1:8880] 15 1 3 5 2 1 1 1 1 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   week = col_date(format = \"\"),\n  ..   category = col_character(),\n  ..   weekly_rank = col_double(),\n  ..   show_title = col_character(),\n  ..   season_title = col_character(),\n  ..   weekly_hours_viewed = col_double(),\n  ..   runtime = col_double(),\n  ..   weekly_views = col_double(),\n  ..   cumulative_weeks_in_top_10 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\nCode\nglimpse(GLOBAL_TOP_10)\n\n\nRows: 8,880\nColumns: 9\n$ week                       &lt;date&gt; 2025-09-28, 2025-09-28, 2025-09-28, 2025-0…\n$ category                   &lt;chr&gt; \"Films (English)\", \"Films (English)\", \"Film…\n$ weekly_rank                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, …\n$ show_title                 &lt;chr&gt; \"KPop Demon Hunters\", \"Ruth & Boaz\", \"The W…\n$ season_title               &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"…\n$ weekly_hours_viewed        &lt;dbl&gt; 32200000, 15900000, 13500000, 15700000, 112…\n$ runtime                    &lt;dbl&gt; 1.6667, 1.5500, 1.7833, 2.4333, 1.8333, 1.7…\n$ weekly_views               &lt;dbl&gt; 19300000, 10300000, 7600000, 6500000, 61000…\n$ cumulative_weeks_in_top_10 &lt;dbl&gt; 15, 1, 3, 5, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, …"
  },
  {
    "objectID": "mp01.html#task-2-data-cleaning",
    "href": "mp01.html#task-2-data-cleaning",
    "title": "Mini-Project #01",
    "section": "Task 2: Data Cleaning",
    "text": "Task 2: Data Cleaning\n\n\nCode\nGLOBAL_TOP_10 &lt;- read_tsv(GLOBAL_TOP_10_FILENAME, show_col_types = FALSE) |&gt;\n  mutate(season_title = if_else(season_title == \"N/A\", NA_character_, season_title))\n\nglimpse(GLOBAL_TOP_10)\n\n\nRows: 8,880\nColumns: 9\n$ week                       &lt;date&gt; 2025-09-28, 2025-09-28, 2025-09-28, 2025-0…\n$ category                   &lt;chr&gt; \"Films (English)\", \"Films (English)\", \"Film…\n$ weekly_rank                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, …\n$ show_title                 &lt;chr&gt; \"KPop Demon Hunters\", \"Ruth & Boaz\", \"The W…\n$ season_title               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"aka Ch…\n$ weekly_hours_viewed        &lt;dbl&gt; 32200000, 15900000, 13500000, 15700000, 112…\n$ runtime                    &lt;dbl&gt; 1.6667, 1.5500, 1.7833, 2.4333, 1.8333, 1.7…\n$ weekly_views               &lt;dbl&gt; 19300000, 10300000, 7600000, 6500000, 61000…\n$ cumulative_weeks_in_top_10 &lt;dbl&gt; 15, 1, 3, 5, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, …"
  },
  {
    "objectID": "mp01.html#task-3-data-import",
    "href": "mp01.html#task-3-data-import",
    "title": "Mini-Project #01",
    "section": "Task 3: Data Import",
    "text": "Task 3: Data Import\n\n\nCode\nCOUNTRY_TOP_10 &lt;- read_tsv(COUNTRY_TOP_10_FILENAME, na = \"N/A\", show_col_types = FALSE)\nglimpse(COUNTRY_TOP_10)\n\n\nRows: 413,620\nColumns: 8\n$ country_name               &lt;chr&gt; \"Argentina\", \"Argentina\", \"Argentina\", \"Arg…\n$ country_iso2               &lt;chr&gt; \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"AR\", \"…\n$ week                       &lt;date&gt; 2025-09-28, 2025-09-28, 2025-09-28, 2025-0…\n$ category                   &lt;chr&gt; \"Films\", \"Films\", \"Films\", \"Films\", \"Films\"…\n$ weekly_rank                &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, …\n$ show_title                 &lt;chr&gt; \"Sonic the Hedgehog 3\", \"KPop Demon Hunters…\n$ season_title               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Bi…\n$ cumulative_weeks_in_top_10 &lt;dbl&gt; 2, 15, 1, 2, 1, 1, 2, 5, 1, 2, 2, 1, 1, 1, …"
  },
  {
    "objectID": "mp01.html#initial-data-exploration",
    "href": "mp01.html#initial-data-exploration",
    "title": "Mini-Project #01",
    "section": "Initial Data Exploration",
    "text": "Initial Data Exploration\n\n\nCode\nif (!require(\"DT\")) install.packages('DT')\n\n\nLoading required package: DT\n\n\nCode\nlibrary(DT)\nGLOBAL_TOP_10 |&gt; \n    head(n=20) |&gt;\n    datatable(options=list(searching=FALSE, info=FALSE))\n\n\n\n\n\n\nCode\nlibrary(stringr)\nformat_titles &lt;- function(df){\n    colnames(df) &lt;- str_replace_all(colnames(df), \"_\", \" \") |&gt; str_to_title()\n    df\n}\n\nGLOBAL_TOP_10 |&gt; \n    mutate(`runtime_(minutes)` = round(60 * runtime)) |&gt;\n    select(-season_title, \n           -runtime) |&gt;\n    format_titles() |&gt;\n    head(n=20) |&gt;\n    datatable(options=list(searching=FALSE, info=FALSE)) |&gt;\n    formatRound(c('Weekly Hours Viewed', 'Weekly Views'))"
  },
  {
    "objectID": "mp01.html#task-4-exploratory-questions",
    "href": "mp01.html#task-4-exploratory-questions",
    "title": "Mini-Project #01",
    "section": "Task 4: Exploratory Questions",
    "text": "Task 4: Exploratory Questions\nQuestion 1: How many different countries does Netflix operate in? (You can use the viewing history as a proxy for countries in which Netflix operates.)\n\n\nCode\nn_countries &lt;- COUNTRY_TOP_10 |&gt; summarise(n = n_distinct(country_name)) |&gt; pull(n)\nn_countries\n\n\n[1] 94\n\n\nNetflix operates in 94 countries.\nQuestion 2: Which non-English-language film has spent the most cumulative weeks in the global top 10? How many weeks did it spend?\n\n\nCode\nnon_en &lt;- GLOBAL_TOP_10 |&gt;\n  filter(category == \"Films (Non-English)\") |&gt;\n  group_by(show_title) |&gt;\n  summarise(max_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(max_weeks)) |&gt;\n  slice(1)\n  non_en\n\n\n# A tibble: 1 × 2\n  show_title                     max_weeks\n  &lt;chr&gt;                              &lt;dbl&gt;\n1 All Quiet on the Western Front        23\n\n\nAmong non-English-language films, All Quiet on the Western Front holds the longest global Top-10 presence with 23 weeks cumulatively\nQuestion 3: What is the longest film (English or non-English) to have ever appeared in the Netflix global Top 10? How long is it in minutes?\n\n\nCode\nlongest_film &lt;- GLOBAL_TOP_10 |&gt;\n  filter(str_detect(category, \"^Films\")) |&gt;\n  mutate(runtime_minutes = round(60 * runtime)) |&gt;\n  group_by(show_title) |&gt;\n  summarize(longest = max(runtime_minutes, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(longest)) |&gt;\n  slice(1)\n\n\nWarning: There were 769 warnings in `summarize()`.\nThe first warning was:\nℹ In argument: `longest = max(runtime_minutes, na.rm = TRUE)`.\nℹ In group 2: `show_title = \"'83\"`.\nCaused by warning in `max()`:\n! no non-missing arguments to max; returning -Inf\nℹ Run `dplyr::last_dplyr_warnings()` to see the 768 remaining warnings.\n\n\nCode\nlongest_film_title   &lt;- longest_film$show_title\nlongest_film_minutes &lt;- longest_film$longest\nlongest_film_title\n\n\n[1] \"Pushpa 2: The Rule (Reloaded Version)\"\n\n\nCode\nlongest_film_minutes\n\n\n[1] 224\n\n\nThe longest film to chart globally is Pushpa 2: The Rule (Reloaded Version) at 224 minutes\nQuestion 4:For each of the four categories, what program has the most total hours of global viewership?\n\n\nCode\ntop_hours &lt;- GLOBAL_TOP_10 |&gt;\n  group_by(category, show_title) |&gt;\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE), .groups=\"drop\") |&gt;\n  group_by(category) |&gt; slice_max(total_hours, n=1, with_ties=FALSE)\n\ntop_hours\n\n\n# A tibble: 4 × 3\n# Groups:   category [4]\n  category            show_title          total_hours\n  &lt;chr&gt;               &lt;chr&gt;                     &lt;dbl&gt;\n1 Films (English)     KPop Demon Hunters    591300000\n2 Films (Non-English) Society of the Snow   235900000\n3 TV (English)        Stranger Things      2967980000\n4 TV (Non-English)    Squid Game           5048300000\n\n\nThe leading program for each category is Films (English): KPop Demon Hunters; Films (Non-English): Society of the Snow; TV (English): Stranger Things; TV (Non-English): Squid Game\nQuestion 5: Which TV show had the longest run in a country’s Top 10? How long was this run and in what country did it occur?\n\n\nCode\nlongest_run &lt;- COUNTRY_TOP_10 |&gt;\n  filter(str_detect(category, \"^TV\")) |&gt;\n  group_by(country_name, show_title) |&gt;\n  summarize(run_weeks = n_distinct(week), .groups = \"drop\") |&gt;\n  arrange(desc(run_weeks)) |&gt;\n  slice(1)\nlongest_run\n\n\n# A tibble: 1 × 3\n  country_name show_title  run_weeks\n  &lt;chr&gt;        &lt;chr&gt;           &lt;int&gt;\n1 Pakistan     Money Heist       128\n\n\nMoney Heist ran 128 weeks in Pakistan.\nQuestion 6: Netflix provides over 200 weeks of service history for all but one country in our data set. Which country is this and when did Netflix cease operations in that country?\n\n\nCode\nno_hist &lt;- COUNTRY_TOP_10 |&gt;\n  group_by(country_name) |&gt;\n  summarize(n_weeks = n_distinct(week), last_week = max(week), .groups = \"drop\") |&gt;\n  arrange(n_weeks)\n\nhead(no_hist, 5) |&gt;\n  format_titles() |&gt;\n  datatable(options = list(searching = FALSE, info = FALSE))\n\n\n\n\n\n\nCode\nno_hist\n\n\n# A tibble: 94 × 3\n   country_name n_weeks last_week \n   &lt;chr&gt;          &lt;int&gt; &lt;date&gt;    \n 1 Russia            35 2022-02-27\n 2 Argentina        222 2025-09-28\n 3 Australia        222 2025-09-28\n 4 Austria          222 2025-09-28\n 5 Bahamas          222 2025-09-28\n 6 Bahrain          222 2025-09-28\n 7 Bangladesh       222 2025-09-28\n 8 Belgium          222 2025-09-28\n 9 Bolivia          222 2025-09-28\n10 Brazil           222 2025-09-28\n# ℹ 84 more rows\n\n\nThe smallest-history country is Russia, last reporting 2022-02-27, with 35 weeks of data.\nQuestion 7: What is the total viewership of the TV show Squid Game? Note that there are three seasons total and we are looking for the total number of hours watched across all seasons.\n\n\nCode\noptions(scipen = 999)  \n\ntotal_hours &lt;- GLOBAL_TOP_10 |&gt;\n  filter(str_detect(show_title, fixed(\"Squid Game\", ignore_case = TRUE))) |&gt;\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE), .groups = \"drop\") |&gt;\n  pull(total_hours)\n\ntotal_hours  \n\n\n[1] 5310000000\n\n\nSquid Game had 5310000000 hours of global view time across all seasons.\nQuestion 8: The movie Red Notice has a runtime of 1 hour and 58 minutes. Approximately how many views did it receive in 2021?\n\n\nCode\nred_runtime_hours &lt;- 1 + 58/60   \nhours &lt;- GLOBAL_TOP_10 |&gt;\n  filter(show_title == \"Red Notice\", year(week) == 2021) |&gt;\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE), .groups = \"drop\") |&gt;\n  pull(total_hours)\n\nviews &lt;- hours / red_runtime_hours\n\nviews\n\n\n[1] 201732203\n\n\nThere are 201,732,203 views for Red Notice in 2021.\nQuestion 9: How many Films reached Number 1 in the US but did not originally debut there? That is, find films that first appeared on the Top 10 chart at, e.g., Number 4 but then became more popular and eventually hit Number 1? What is the most recent film to pull this off?\n\n\nCode\nfilms &lt;- COUNTRY_TOP_10 |&gt; filter(category == \"Films\")\nus_films &lt;- films |&gt; filter(country_name == \"United States\")\n\never_us_no1 &lt;- us_films |&gt;\n  group_by(show_title) |&gt;\n  summarise(ever_us_no1 = any(weekly_rank == 1, na.rm = TRUE), .groups = \"drop\")\n\nus_most_recent_1 &lt;- us_films |&gt;\n  filter(weekly_rank == 1) |&gt;\n  group_by(show_title) |&gt;\n  summarise(us_most_recent_week_at_1 = max(week, na.rm = TRUE), .groups = \"drop\")\n\nus_first_week &lt;- us_films |&gt;\n  group_by(show_title) |&gt;\n  summarise(us_first_week = min(week, na.rm = TRUE), .groups = \"drop\")\n\ndebut_week &lt;- films |&gt;\n  group_by(show_title) |&gt;\n  summarise(debut_week = min(week, na.rm = TRUE), .groups = \"drop\")\n\ndebut_countries &lt;- films |&gt;\n  inner_join(debut_week, by = \"show_title\") |&gt;\n  filter(week == debut_week) |&gt;\n  group_by(show_title) |&gt;\n  summarise(debut_countries = list(sort(unique(country_name))), .groups = \"drop\") |&gt;\n  mutate(debut_in_us = purrr::map_lgl(debut_countries, ~ \"United States\" %in% .x))\n\nlibrary(purrr)\n\nsummary_tbl &lt;- ever_us_no1 |&gt;\n  filter(ever_us_no1) |&gt;\n  left_join(us_most_recent_1, by = \"show_title\") |&gt;\n  left_join(us_first_week,     by = \"show_title\") |&gt;\n  left_join(debut_week,        by = \"show_title\") |&gt;\n  left_join(debut_countries,   by = \"show_title\") |&gt;\n  filter(!debut_in_us) |&gt;\n  arrange(desc(us_most_recent_week_at_1))\n\ncount  &lt;- nrow(summary_tbl)\nrecent &lt;- if (count &gt; 0) summary_tbl$show_title[1] else NA_character_\nrecent_date &lt;- if (count &gt; 0) as.character(summary_tbl$us_most_recent_week_at_1[1]) else NA_character_\n\nhead(summary_tbl, 40) |&gt;\n  transmute(\n    Title = show_title,\n    `Global Debut Week` = debut_week,\n    `Debut Countries` = sapply(debut_countries, paste, collapse = \", \"),\n    `First Week in US` = us_first_week,\n    `Most Recent US #1 Week` = us_most_recent_week_at_1\n  )\n\n\n# A tibble: 33 × 5\n   Title                `Global Debut Week` `Debut Countries` `First Week in US`\n   &lt;chr&gt;                &lt;date&gt;              &lt;chr&gt;             &lt;date&gt;            \n 1 Plane                2024-09-15          Ireland, Malta, … 2025-06-15        \n 2 The Wild Robot       2025-04-20          Australia         2025-05-25        \n 3 Despicable Me 4      2025-01-19          Australia, New Z… 2025-03-02        \n 4 Venom: The Last Dan… 2025-01-26          Bangladesh, Indi… 2025-03-02        \n 5 To Catch a Killer    2023-08-20          Canada            2025-02-23        \n 6 Despicable Me 2      2021-10-10          Canada            2022-02-06        \n 7 Focus                2021-07-04          Latvia            2024-11-17        \n 8 Bad Boys: Ride or D… 2024-09-08          Bangladesh, Indi… 2024-10-13        \n 9 The Garfield Movie   2024-08-25          Pakistan          2024-09-22        \n10 Jack Reacher: Never… 2021-10-03          Denmark, Finland… 2024-08-04        \n# ℹ 23 more rows\n# ℹ 1 more variable: `Most Recent US #1 Week` &lt;date&gt;\n\n\n33 films debuted outside the US but later reached #1 in the US; the most recent is Plane (US #1 week: 2025-06-22).\nQuestion 10: Which TV show/season hit the top 10 in the most countries in its debut week? In how many countries did it chart?\n\n\nCode\ndebut &lt;- COUNTRY_TOP_10 |&gt;\n  group_by(show_title, season_title) |&gt;\n  summarise(debut_week = min(week), .groups = \"drop\")\n\n\nspread &lt;- COUNTRY_TOP_10 |&gt;\n  inner_join(debut, by = c(\"show_title\",\"season_title\")) |&gt;\n  filter(week == debut_week, str_detect(category, \"^TV\")) |&gt;\n  group_by(show_title, season_title) |&gt;\n  summarise(countries = n_distinct(country_name), .groups = \"drop\") |&gt;\n  arrange(desc(countries)) |&gt;\n  slice(1)\n\ntitle &lt;- paste0(spread$show_title, ifelse(is.na(spread$season_title),\"\", paste0(\" — \", spread$season_title)))\nn     &lt;- spread$countries[1]\n\ntitle\n\n\n[1] \"Emily in Paris — Emily in Paris: Season 2\"\n\n\nCode\nn\n\n\n[1] 94\n\n\nIn its debut week, Emily in Paris — Emily in Paris: Season 2 charted in 94 countries.\n##Task 5: Stranger Things Press Release\nStranger Things; Whats Next!?\n\n\nCode\nst_global &lt;- GLOBAL_TOP_10 %&gt;%\n  mutate(week = as.Date(week)) %&gt;%\n  filter(str_detect(category, \"^TV\"),\n         str_detect(show_title, fixed(\"Stranger Things\", ignore_case = TRUE)))\n\nst_total_hours  &lt;- sum(st_global$weekly_hours_viewed, na.rm = TRUE)\nst_weeks_global &lt;- dplyr::n_distinct(st_global$week)\n\n\nst_countries &lt;- COUNTRY_TOP_10 %&gt;%\n  mutate(week = as.Date(week)) %&gt;%\n  filter(str_detect(show_title, fixed(\"Stranger Things\", ignore_case = TRUE))) %&gt;%\n  summarise(n = dplyr::n_distinct(country_name)) %&gt;%\n  pull(n)\n\n\ntv_hours &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(str_detect(category, \"^TV\")) %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  arrange(desc(total_hours))\n\nst_rows &lt;- which(str_detect(tv_hours$show_title, fixed(\"Stranger Things\", ignore_case = TRUE)))\nst_rank &lt;- if (length(st_rows)) st_rows[1] else NA_integer_\n\n\npeer_tv &lt;- head(tv_hours$show_title, 3)\n\n\ntv_hours_en &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(category == \"TV (English)\") %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  arrange(desc(total_hours))\n\nst_rows_en &lt;- which(str_detect(tv_hours_en$show_title, fixed(\"Stranger Things\", ignore_case = TRUE)))\nst_rank_en &lt;- if (length(st_rows_en)) st_rows_en[1] else NA_integer_\nst_global\n\n\n# A tibble: 50 × 9\n   week       category   weekly_rank show_title season_title weekly_hours_viewed\n   &lt;date&gt;     &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;                      &lt;dbl&gt;\n 1 2022-10-09 TV (Engli…           9 Stranger … Stranger Th…             9420000\n 2 2022-10-02 TV (Engli…           8 Stranger … Stranger Th…            10340000\n 3 2022-09-18 TV (Engli…           9 Stranger … Stranger Th…            13480000\n 4 2022-09-11 TV (Engli…           8 Stranger … Stranger Th…            16560000\n 5 2022-09-04 TV (Engli…           5 Stranger … Stranger Th…            20280000\n 6 2022-08-28 TV (Engli…           4 Stranger … Stranger Th…            23640000\n 7 2022-08-21 TV (Engli…           3 Stranger … Stranger Th…            28800000\n 8 2022-08-14 TV (Engli…           4 Stranger … Stranger Th…            35310000\n 9 2022-08-07 TV (Engli…           4 Stranger … Stranger Th…            44760000\n10 2022-08-07 TV (Engli…          10 Stranger … Stranger Th…            17040000\n# ℹ 40 more rows\n# ℹ 3 more variables: runtime &lt;dbl&gt;, weekly_views &lt;dbl&gt;,\n#   cumulative_weeks_in_top_10 &lt;dbl&gt;\n\n\nCode\nst_total_hours\n\n\n[1] 2967980000\n\n\nCode\nst_countries\n\n\n[1] 93\n\n\nCode\nst_weeks_global\n\n\n[1] 20\n\n\nCode\nst_rank\n\n\n[1] 2\n\n\nCode\npeer_tv \n\n\n[1] \"Squid Game\"      \"Stranger Things\" \"Wednesday\"      \n\n\nStranger Things season 5 will debut later this year in 2025. The previous four seasons of the show have lined up season 5 perfectly. The last four seasons have accumulated 2967980000 of viewership and was Top 10 in 93 countries. These are very impressive stats! This shows that the show has proven to be popular across many countries acquiring and enormous amount of views. The previous four seasons also spent 20 weeks in the top ten position globally and ranks 2 currently among the top three titles Squid Game, Stranger Things, Wednesday. Because the last four seasons have sat with other top titles and has relatively retained a strong rank among them, season 5 is sure to not disappoint. So everyone get ready, turn on your tv, lets head to Netflix and enjoy the show!!\n##Task 6: Netflix in India Press Release\nNetflix Hits Bollywood!\n\n\nCode\nINDIA &lt;- COUNTRY_TOP_10 |&gt; filter(country_name == \"India\")\nUSA   &lt;- COUNTRY_TOP_10 |&gt; filter(country_name == \"United States\")\n\nindia_first_titles &lt;- INDIA |&gt; distinct(show_title) |&gt;\n  anti_join(USA |&gt; distinct(show_title), by = \"show_title\")\n\nviews_base &lt;- GLOBAL_TOP_10 |&gt;\n  filter(show_title %in% india_first_titles$show_title) |&gt;\n  mutate(\n    year         = year(week),\n    runtime      = suppressWarnings(as.numeric(runtime)),       \n    weekly_views = suppressWarnings(as.numeric(weekly_views)),  \n    views_est    = dplyr::coalesce(\n      weekly_views,\n      if_else(!is.na(runtime) & runtime &gt; 0, weekly_hours_viewed / runtime, NA_real_)\n    )\n  )\n\nlatest_india_week &lt;- INDIA |&gt;\n  filter(show_title %in% india_first_titles$show_title) |&gt;\n  group_by(show_title) |&gt;\n  summarise(india_latest_week = max(week, na.rm = TRUE), .groups = \"drop\")\n\nviews_per_title &lt;- views_base |&gt;\n  group_by(show_title) |&gt;\n  summarise(all_time_views = sum(views_est, na.rm = TRUE), .groups = \"drop\")\n\nrecent_top3 &lt;- latest_india_week |&gt;\n  inner_join(views_per_title, by = \"show_title\") |&gt;\n  arrange(desc(india_latest_week)) |&gt;\n  slice_head(n = 3)\n\nt1  &lt;- if (nrow(recent_top3) &gt;= 1) recent_top3$show_title[1] else NA_character_\nt1v &lt;- if (nrow(recent_top3) &gt;= 1) recent_top3$all_time_views[1] else NA_real_\nt2  &lt;- if (nrow(recent_top3) &gt;= 2) recent_top3$show_title[2] else NA_character_\nt2v &lt;- if (nrow(recent_top3) &gt;= 2) recent_top3$all_time_views[2] else NA_real_\nt3  &lt;- if (nrow(recent_top3) &gt;= 3) recent_top3$show_title[3] else NA_character_\nt3v &lt;- if (nrow(recent_top3) &gt;= 3) recent_top3$all_time_views[3] else NA_real_\n\n\ntotal_views_all_time &lt;- sum(views_per_title$all_time_views, na.rm = TRUE)\n\n\nstart_year &lt;- min(views_base$year, na.rm = TRUE)\nfirst3     &lt;- start_year + 0:2\n\nviews_first3_years &lt;- views_base |&gt;\n  filter(year %in% first3) |&gt;\n  summarise(total_views = sum(views_est, na.rm = TRUE), .groups = \"drop\") |&gt;\n  pull(total_views)\n\nshare_first3 &lt;- ifelse(total_views_all_time &gt; 0,\n                       views_first3_years / total_views_all_time, NA_real_)\n\nwindow_start_all &lt;- min(GLOBAL_TOP_10$week, na.rm = TRUE)\nwindow_end_all   &lt;- max(GLOBAL_TOP_10$week, na.rm = TRUE)\nt1\n\n\n[1] \"Bon Appétit, Your Majesty\"\n\n\nCode\nscales::comma(round(t1v))\n\n\n[1] \"38,400,000\"\n\n\nCode\nscales::comma(round(total_views_all_time))\n\n\n[1] \"2,742,900,000\"\n\n\nCode\nscales::comma(round(views_first3_years))\n\n\n[1] \"624,500,000\"\n\n\nCode\nifelse(is.na(share_first3), \"N/A\", paste0(round(100*share_first3), \"%\"))\n\n\n[1] \"23%\"\n\n\nNetflix, who doesnt know that name around the globe? Netflix has recently broke into the Indian market and its creating a lot of buzz. So far the total views all time in India have been 2,742,900,000. This shows that there is strong viewership in India and that Netflix has a lot of gain coming from this market. Some of the top recent successes are Bon Appétit, Your Majesty (38,400,000 views), Dhadak 2 (1,300,000 views), and Inspector Zende (7,800,000 views), reflecting strong momentum within the nation! 624,500,000 out of those all-time views (23%) arrived in the first three years. Thus showing us long term growth stands strong within India. The Indian people are watching and are waiting for more!\n##Task 7: 3rd Press Release\nCurrent Best For Netflix\n\n\nCode\nGLOBAL_TOP_10  &lt;- GLOBAL_TOP_10  %&gt;%\n  mutate(\n    week         = as.Date(week),\n    runtime      = suppressWarnings(as.numeric(runtime)),\n    weekly_views = suppressWarnings(as.numeric(weekly_views)),\n    views_est    = dplyr::coalesce(weekly_views,\n                                   if_else(!is.na(runtime) & runtime &gt; 0,\n                                           weekly_hours_viewed / runtime, NA_real_))\n  )\n\nCOUNTRY_TOP_10 &lt;- COUNTRY_TOP_10 %&gt;%\n  mutate(week = as.Date(week))\n\n\nusa_films_titles &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(country_name == \"United States\", category == \"Films\") %&gt;%\n  distinct(show_title)\n\nnon_us_film_titles &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(category == \"Films\") %&gt;%\n  distinct(show_title) %&gt;%\n  anti_join(usa_films_titles, by = \"show_title\")\n\n\nfilm_views &lt;- GLOBAL_TOP_10 %&gt;%\n  filter(str_detect(category, \"^Films\"),\n         show_title %in% non_us_film_titles$show_title) %&gt;%\n  group_by(show_title) %&gt;%\n  summarise(total_views_est = sum(views_est, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  arrange(desc(total_views_est))\n\nbest_film_title &lt;- if (nrow(film_views)) film_views$show_title[1] else NA_character_\nbest_film_views &lt;- if (nrow(film_views)) film_views$total_views_est[1] else NA_real_\n\nall_countries &lt;- COUNTRY_TOP_10 %&gt;% distinct(country_name) %&gt;% arrange(country_name) %&gt;% pull(country_name)\n\nshown_countries &lt;- COUNTRY_TOP_10 %&gt;%\n  filter(show_title == best_film_title, category == \"Films\") %&gt;%\n  distinct(country_name) %&gt;%\n  arrange(country_name) %&gt;%\n  pull(country_name)\n\nnot_shown_countries &lt;- setdiff(all_countries, shown_countries)\n\nn_shown     &lt;- length(shown_countries)\nn_not_shown &lt;- length(not_shown_countries)\n\nbest_film_title\n\n\n[1] \"Dr. Seuss' The Grinch\"\n\n\nCode\nbest_film_views\n\n\n[1] 81200000\n\n\nCode\nn_shown\n\n\n[1] 84\n\n\nCode\nn_not_shown\n\n\n[1] 10\n\n\nWhat is the next best for Netflix? Have you ever wondered what titles were grossing outside of the us with a lot of viewer count? Believe it or not it seems to be Dr. Seuss’ The Grinch Even though this seems to be a film that has come out many times with remakes, it still is very successful. With 81200000 views outside of the US, it shows strong precense globally. Currently it is being shown in 84 countries and not being shown in 10 countries. For this holiday season Netflix should target this movie in all countries possible. This would drive more global and customer expansion with a title that has already proven to be successful!!"
  }
]